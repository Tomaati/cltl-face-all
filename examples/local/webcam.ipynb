{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the modules and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltl_face_all.agegender import AgeGender\n",
    "from cltl_face_all.arcface import ArcFace\n",
    "from cltl_face_all.arcface import calc_angle_distance\n",
    "from cltl_face_all.face_alignment import FaceDetection\n",
    "from contextlib import contextmanager\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "HERE = os.getcwd()\n",
    "\n",
    "@contextmanager\n",
    "def video_capture(*args, **kwargs):\n",
    "    cap = cv2.VideoCapture(*args, **kwargs)\n",
    "    try:\n",
    "        yield cap\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "\n",
    "def yield_images():\n",
    "    # capture video\n",
    "    # Configure the webcam number if you have more than one.\n",
    "    with video_capture(0) as cap:\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "        while True:\n",
    "            # get video frame\n",
    "            ret, img = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                raise RuntimeError(\"Failed to capture image\")\n",
    "\n",
    "            img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            yield img_RGB\n",
    "\n",
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=0.8, thickness=1):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n",
    "\n",
    "existing_embs_ = glob(os.path.join(HERE, f'../../your-faces/*/*.npy'))\n",
    "existing_embs = []\n",
    "existing_names = []\n",
    "\n",
    "for ee_ in existing_embs_:\n",
    "    existing_names.append(os.path.basename(ee_).split('.npy')[0])\n",
    "    existing_embs.append(np.load(ee_).reshape(1, 512))\n",
    "\n",
    "existing_embs  = np.concatenate(existing_embs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the age-gender, arcface, and face-detection classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[*] load ckpt from /home/tk/.virtualenvs/dev-python-3.7/lib/python3.7/site-packages/cltl_face_all/arcface/./pretrained_models/arc_res50/e_8_b_40000.ckpt\n"
     ]
    }
   ],
   "source": [
    "ag = AgeGender(device='cpu')\n",
    "af = ArcFace(device='cpu')\n",
    "fd = FaceDetection(device='cpu', face_detector='sfd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run over the webcam images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n",
      "number of faces in this frame: 1\n"
     ]
    }
   ],
   "source": [
    "for idx, img in enumerate(yield_images()):\n",
    "    bboxes = fd.detect_faces(img[np.newaxis, ...])\n",
    "    landmarks = fd.detect_landmarks(img[np.newaxis, ...], bboxes)\n",
    "    faces = fd.crop_and_align(img[np.newaxis, ...], bboxes, landmarks)\n",
    "\n",
    "    # There is only one image per batch. fd returns a list\n",
    "    bbox = bboxes[0]\n",
    "    landmark = landmarks[0]\n",
    "    face = faces[0]\n",
    "\n",
    "    face_threshold = 0.85\n",
    "\n",
    "    if len(bbox) > 0:\n",
    "        print(f\"number of faces in this frame: {len(bbox)}\")\n",
    "\n",
    "        # ag and af return a np.ndarray\n",
    "        age, gender = ag.predict(face)\n",
    "        embeddings = af.predict(face)\n",
    "\n",
    "        # print(len(bbox), len(landmark), len(face), len(age), len(gender), len(embeddings))\n",
    "\n",
    "        for bb, lm, a, g, emb in zip(bbox, landmark, age, gender, embeddings):\n",
    "            x1, y1, x2, y2, prob = bb\n",
    "            \n",
    "            if prob < face_threshold:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "            label = f\"{str(round(prob*100, 1))} % face\"\n",
    "            draw_label(img, (x1, y2), label, font_scale=0.5, thickness=1)\n",
    "\n",
    "            for lm in landmark:\n",
    "                for xy in lm:\n",
    "                    cv2.circle(img, (int(xy[0]), int(xy[1])), 1, (0,255,0), -1)\n",
    "\n",
    "            label = f\"{int(a)} years old, {str(round(g*100, 1))} % female\"\n",
    "            draw_label(img, (x1, y1), label, font_scale=0.5, thickness=1)\n",
    "\n",
    "            emb = emb.reshape(1, 512)\n",
    "            dists = calc_angle_distance(emb, existing_embs)\n",
    "\n",
    "            candidate, dist = existing_names[np.argmin(dists)], np.min(dists)\n",
    "            angle_dist_threshold = 1.0\n",
    "            if dist < angle_dist_threshold:\n",
    "                label = f\"{candidate}\"\n",
    "                draw_label(img, (x2, y2), label, font_scale=0.5, thickness=1)\n",
    "\n",
    "    img = cv2.resize(img, (img.shape[1]*2, img.shape[0]*2))\n",
    "    cv2.imshow(\"result\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    for idx, fc in enumerate(face):\n",
    "        fc = cv2.resize(fc, (fc.shape[1]*2, fc.shape[0]*2))\n",
    "        cv2.imshow(f\"cropped and aligned {idx}\", cv2.cvtColor(fc, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if key == 27:  # ESC\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('dev-python-3.7')",
   "language": "python",
   "name": "python37964bitdevpython378e162af75d134820b03d49898b79756f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}