{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frist create a directory of your name at REPO-ROOT/your-faces/\n",
    "\n",
    "Write your name in `your_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "HERE = os.getcwd()\n",
    "\n",
    "your_name = \"Tae\"\n",
    "\n",
    "shutil.rmtree(os.path.join(HERE, f'../your-faces/{your_name}/'), ignore_errors=True)\n",
    "os.makedirs(os.path.join(HERE, f'../your-faces/{your_name}/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the modules and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltl_face_all.arcface import ArcFace\n",
    "from cltl_face_all.face_alignment import FaceDetection\n",
    "from contextlib import contextmanager\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "@contextmanager\n",
    "def video_capture(*args, **kwargs):\n",
    "    cap = cv2.VideoCapture(*args, **kwargs)\n",
    "    try:\n",
    "        yield cap\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "\n",
    "def yield_images():\n",
    "    # capture video\n",
    "    with video_capture(0) as cap:\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "        while True:\n",
    "            # get video frame\n",
    "            ret, img = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                raise RuntimeError(\"Failed to capture image\")\n",
    "\n",
    "            img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            yield img_RGB\n",
    "\n",
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=0.8, thickness=1):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the arcface, and face-detection classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] load ckpt from /home/tk/.virtualenvs/dev-python-3.7/lib/python3.7/site-packages/cltl_face_all/arcface/./pretrained_models/arc_res50/e_8_b_40000.ckpt\n"
     ]
    }
   ],
   "source": [
    "af = ArcFace(device='cpu')\n",
    "fd = FaceDetection(device='cpu', face_detector='blazeface')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## move around your face. This process ends when 100 faces of yours is well taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/dev-python-3.7/lib/python3.7/site-packages/cltl_face_all/face_alignment/matlab_cp2tform.py:84: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  r, _, _, _ = lstsq(X, U)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 100\n",
      "2 / 100\n",
      "3 / 100\n",
      "4 / 100\n",
      "5 / 100\n",
      "6 / 100\n",
      "7 / 100\n",
      "8 / 100\n",
      "9 / 100\n",
      "10 / 100\n",
      "11 / 100\n",
      "12 / 100\n",
      "13 / 100\n",
      "14 / 100\n",
      "15 / 100\n",
      "16 / 100\n",
      "17 / 100\n",
      "18 / 100\n",
      "19 / 100\n",
      "20 / 100\n",
      "21 / 100\n",
      "22 / 100\n",
      "23 / 100\n",
      "24 / 100\n",
      "25 / 100\n",
      "26 / 100\n",
      "27 / 100\n",
      "28 / 100\n",
      "29 / 100\n",
      "30 / 100\n",
      "31 / 100\n",
      "32 / 100\n",
      "33 / 100\n",
      "34 / 100\n",
      "35 / 100\n",
      "36 / 100\n",
      "37 / 100\n",
      "38 / 100\n",
      "39 / 100\n",
      "40 / 100\n",
      "41 / 100\n",
      "42 / 100\n",
      "43 / 100\n",
      "44 / 100\n",
      "45 / 100\n",
      "46 / 100\n",
      "47 / 100\n",
      "48 / 100\n",
      "49 / 100\n",
      "50 / 100\n",
      "51 / 100\n",
      "52 / 100\n",
      "53 / 100\n",
      "54 / 100\n",
      "55 / 100\n",
      "56 / 100\n",
      "57 / 100\n",
      "58 / 100\n",
      "59 / 100\n",
      "60 / 100\n",
      "61 / 100\n",
      "62 / 100\n",
      "63 / 100\n",
      "64 / 100\n",
      "65 / 100\n",
      "66 / 100\n",
      "67 / 100\n",
      "68 / 100\n",
      "69 / 100\n",
      "70 / 100\n",
      "71 / 100\n",
      "72 / 100\n",
      "73 / 100\n",
      "74 / 100\n",
      "75 / 100\n",
      "76 / 100\n",
      "77 / 100\n",
      "78 / 100\n",
      "79 / 100\n",
      "80 / 100\n",
      "81 / 100\n",
      "82 / 100\n",
      "83 / 100\n",
      "84 / 100\n",
      "85 / 100\n",
      "86 / 100\n",
      "87 / 100\n",
      "88 / 100\n",
      "89 / 100\n",
      "90 / 100\n",
      "91 / 100\n",
      "92 / 100\n",
      "93 / 100\n",
      "94 / 100\n",
      "95 / 100\n",
      "96 / 100\n",
      "97 / 100\n",
      "98 / 100\n",
      "99 / 100\n",
      "100 / 100\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "num_to_take = 100\n",
    "for idx, img in enumerate(yield_images()):\n",
    "    bboxes = fd.detect_faces(img[np.newaxis, ...])\n",
    "    landmarks = fd.detect_landmarks(img[np.newaxis, ...], bboxes)\n",
    "    faces = fd.crop_and_align(img[np.newaxis, ...], bboxes, landmarks)\n",
    "\n",
    "    # There is only one image per batch. fd returns a list\n",
    "    bbox = bboxes[0]\n",
    "    landmark = landmarks[0]\n",
    "    face = faces[0]\n",
    "\n",
    "    if len(bbox) == 0:\n",
    "        continue\n",
    "    # Only take the first face\n",
    "    bbox = bbox[0]\n",
    "    landmark = landmark[0]\n",
    "    face = face[0]\n",
    "\n",
    "    # add the dummy axis\n",
    "    bbox = bbox[np.newaxis, ...]\n",
    "    landmark = landmark[np.newaxis, ...]\n",
    "    face = face[np.newaxis, ...]\n",
    "\n",
    "    face_threshold = 0.85\n",
    "    \n",
    "    if len(bbox) > 0 and bbox[0, -1] > face_threshold:\n",
    "        count +=1\n",
    "\n",
    "        print(f\"{count} / {num_to_take}\")\n",
    "        # ag and af return a np.ndarray\n",
    "        embeddings = af.predict(face)\n",
    "\n",
    "        with open(os.path.join(HERE, f'../your-faces/{your_name}/{idx}.npy'), 'wb') as stream:\n",
    "            np.save(stream, embeddings)\n",
    "\n",
    "        # print(len(bbox), len(landmark), len(face), len(age), len(gender), len(embeddings))\n",
    "\n",
    "        for bb, lm in zip(bbox, landmark):\n",
    "            x1, y1, x2, y2, prob = bb\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "            label = f\"{str(round(prob*100, 1))} % face\"\n",
    "            draw_label(img, (x1, y2), label, font_scale=0.5, thickness=1)\n",
    "\n",
    "            for lm in landmark:\n",
    "                for xy in lm:\n",
    "                    cv2.circle(img, (int(xy[0]), int(xy[1])), 1, (0,255,0), -1)\n",
    "\n",
    "    img = cv2.resize(img, (img.shape[1]*2, img.shape[0]*2))\n",
    "    cv2.imshow(\"result\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    for idx, fc in enumerate(face):\n",
    "        fc = cv2.resize(fc, (fc.shape[1]*2, fc.shape[0]*2))\n",
    "        cv2.imshow(f\"cropped and aligned {idx}\", cv2.cvtColor(fc, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if key == 27 or count == num_to_take:  # ESC\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the faces and get the best 50 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from cltl_face_all.arcface import calc_angle_distance\n",
    "\n",
    "embs_ = glob(os.path.join(HERE, f'../your-faces/{your_name}/*npy'))\n",
    "embs = []\n",
    "\n",
    "for emb in embs_:\n",
    "    with open(emb, 'rb') as stream:\n",
    "        embs.append(np.load(stream))\n",
    "\n",
    "embs = np.concatenate(embs)\n",
    "\n",
    "dists = calc_angle_distance(embs, embs)\n",
    "\n",
    "indexes = dists.mean(axis=1).argsort()[:len(dists.mean(axis=1)) // 2]\n",
    "\n",
    "embs = embs[indexes]\n",
    "\n",
    "emb_mean = embs.mean(axis=0)\n",
    "emb_final = emb_mean / np.linalg.norm(emb_mean)\n",
    "\n",
    "with open(os.path.join(HERE, f'../your-faces/{your_name}.npy'), 'wb') as stream:\n",
    "    np.save(stream, emb_final)\n",
    "\n",
    "shutil.rmtree(os.path.join(HERE, f'../your-faces/{your_name}/'), ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('dev-python-3.7')",
   "language": "python",
   "name": "python37964bitdevpython378e162af75d134820b03d49898b79756f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
